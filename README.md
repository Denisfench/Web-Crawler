**To run the web crawler, please follow the instructions below:**

1. Install project dependencies from the requirements.txt file by running pip3 install -r requirements.txt (Note: time and urllib modules shouldn't have been included in the requirements file). 
2. Run the app using python3 app.py 
3. Enter a search query 
4. URLs that are currently being crawled will be displayed on the screen. Also, a `log_file.csv will be generated containing the name of the URL crawled, response code, novelty score, importance score, URL rank, the time URL was visited, and the webpage size. 

Files contained in the project and their short description:

- app.py the crawler application file.
- requirements.txt a file containing Python dependencies for the project
- demo_log_file.csv the log file from the demo on Monday (09.20.2021)
- log_files: a directory containing a log file for the paris texas query. 

*Please discard other files in the folder.*